{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6a6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "##############################################################################\n",
    "##  Super Composite Likelihood algorithm.\n",
    "##\n",
    "##  Copyright 2021 Daniel Wilson and Alejandra Vergara.\n",
    "##  All rights reserved.\n",
    "##\n",
    "##############################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import msprime\n",
    "import math\n",
    "import random\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import tskit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import lmfit\n",
    "import time as time\n",
    "import scipy.stats as stats\n",
    "from numpy.random import rand\n",
    "from scipy.stats import poisson\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "from lmfit import Minimizer, Parameters, fit_report\n",
    "from IPython.display import SVG, display, Math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#!msprime --version\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7899552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation of coalescent time considering theta and migrations\n",
    "\n",
    "def simulate_tree_MM(samp_size, L):\n",
    "    \"\"\"\n",
    "    Coalescent simulation with msprime: Population structure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Sample_size: List of sequences in the sample. Each sample is independent.\n",
    "    L : Length of the sequences (integer).\n",
    "    N: Independent replicates of the coalescent for a sample of n sequences into d demes. \n",
    "    Seed: The process to be unique.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Discrete-deme model of population structure in which d panmictic populations\n",
    "    exchange migrants according to the rates defined in a d × d matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    demography = msprime.Demography()\n",
    "    demography.add_population(name=\"deme_1\", initial_size=1)\n",
    "    demography.add_population(name=\"deme_2\", initial_size=1)\n",
    "    demography.set_symmetric_migration_rate(populations=[\"deme_1\", \"deme_2\"], rate=0.1/2)\n",
    "#     demography.set_migration_rate(source=\"deme_1\", dest=\"deme_2\", rate=M/2)\n",
    "#     demography.set_migration_rate(source=\"deme_2\", dest=\"deme_1\", rate=M/2)\n",
    "    return msprime.sim_ancestry(samples={\"deme_1\": samp_size_per_deme, \"deme_2\": samp_size_per_deme},\n",
    "    #return msprime.sim_ancestry(samples={\"deme_1\": samp_size_per_deme, \"deme_2\": samp_size_per_deme, \"deme_3\": samp_size_per_deme},\n",
    "                                demography=demography, \n",
    "                                sequence_length=L,\n",
    "                                #record_migrations=True,\n",
    "                                #discrete_genome=True,\n",
    "                                #model=\"hudson\",\n",
    "                                num_labels=True,\n",
    "                                ploidy = 1)\n",
    "#                                 random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc249828",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation of coalescent time \n",
    "\n",
    "def simulate_tree_M(samp_size, L):\n",
    "    \"\"\"\n",
    "    Coalescent simulation with msprime: Population structure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Sample_size: List of sequences in the sample. Each sample is independent.\n",
    "    L : Length of the sequences (integer).\n",
    "    N: Independent replicates of the coalescent for a sample of n sequences into d demes. \n",
    "    Seed: The process to be unique.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Discrete-deme model of population structure in which d panmictic populations\n",
    "    exchange migrants according to the rates defined in a d × d matrix.\n",
    "    \"\"\"\n",
    "#msprime.sim_ancestry\n",
    "    print(\"Done\")\n",
    "    return msprime.sim_ancestry(samp_size,\n",
    "                                sequence_length=L,\n",
    "                                discrete_genome=True,\n",
    "                                Ne = 1,\n",
    "                                ploidy = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6781c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branches calculation \n",
    "# where ts -> simulate_tree_MM(samp_size, L)\n",
    "\n",
    "def calc_branches(ts, theta):\n",
    "    \"\"\"\n",
    "    Branches calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : simulator of coalesce events\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Mutations and  over the node IDs in this tree\n",
    "    \"\"\"\n",
    "\n",
    "    ts.dump(\"big_tree.trees\")\n",
    "    tree = ts.first()\n",
    "    first_edges = next(ts.edge_diffs())\n",
    "    node_times = ts.tables.nodes.time\n",
    "    model = msprime.JC69()\n",
    "    mut = msprime.sim_mutations(sims_reps, rate=0.01/2, random_seed=1, model=model, keep=True) \n",
    "    theta_msprime = mut.diversity()\n",
    "    mutas = mut.num_mutations\n",
    "    branch_lengths_above_node = np.zeros(ts.num_nodes)\n",
    "    branch_load = np.zeros(ts.num_nodes)\n",
    "   \n",
    "\n",
    "    for edge in first_edges.edges_in:\n",
    "        branch_lengths_above_node[edge.id] = node_times[edge.parent] - node_times[edge.child]\n",
    "        if edge.child != tree.root:\n",
    "            branch_load[edge.id] = stats.poisson.rvs((theta/2)*branch_lengths_above_node[edge.id])\n",
    "\n",
    "    #colour map shows in which population samples coalesced\n",
    "#     colour_map = {0:\"red\", 1:\"blue\"}\n",
    "#     node_colours = {u: colour_map[tree.population(u)] for u in tree.nodes()}\n",
    "#     display(SVG(tree.draw(format=\"SVG\",width=800, height=400,\n",
    "#                         node_colours=node_colours)))\n",
    "    \n",
    "#     print(branch_lengths_above_node)\n",
    "    return branch_load, branch_lengths_above_node, theta_msprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3429f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Marginal probability\n",
    "### Calculate pairwise distance matrix from tree and # mutations per branch\n",
    "# where ts -> simulate_tree_MM(samp_size, L) and branch -> calc_branches(ts, theta)\n",
    "\n",
    "def calc_pi(ts, branch):\n",
    "    \"\"\"\n",
    "    Pi calculation\n",
    "    Calculate pairwise distance matrix from tree and number of mutations per branch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Discrete-deme model of population structure in which d panmictic populations\n",
    "    exchange migrants according to the rates defined in a d × d matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    tree = ts.first()\n",
    "    first_edges = next(ts.edge_diffs())\n",
    "    node_times = ts.tables.nodes.time\n",
    "    pi_n = np.zeros((ts.num_nodes,ts.num_nodes))\n",
    "    pi_d2 = np.zeros((ts.num_nodes,ts.num_nodes))\n",
    "    pi = np.zeros((samp_size,samp_size))\n",
    "    \n",
    "    \n",
    "    childs_and_parents = {}\n",
    "    parent_to_childs = {}\n",
    "    for edge in first_edges.edges_in:\n",
    "        childs_and_parents[edge.child] = edge.parent\n",
    "    \n",
    "    childs_and_ancestors = {}\n",
    "    for i in childs_and_parents: # child\n",
    "        j = childs_and_parents[i] #parent\n",
    "        childs_and_ancestors[i] = [j]\n",
    "        while j in childs_and_parents:\n",
    "            j = childs_and_parents[j]\n",
    "            childs_and_ancestors[i].append(j)\n",
    "    #parent_to_childs = {v: k for k, v in childs_and_ancestors.items()}\n",
    "\n",
    "    childs_and_distances2ancestors = {}\n",
    "    childs_and_dis2anc_mut = {}\n",
    "    for i in childs_and_ancestors:\n",
    "        js = childs_and_ancestors[i]\n",
    "        if edge.child != tree.root:\n",
    "        #childs_and_distances2ancestors[i] = [node_times[j] - node_times[i] for j in js]\n",
    "            childs_and_distances2ancestors[i] = [1 for j in js] #sum all mutations up for chil to parents \n",
    "            childs_and_dis2anc_mut[i] = [branch[i] for j in js]\n",
    "            \n",
    "\n",
    "    for i in childs_and_distances2ancestors:\n",
    "        j = childs_and_ancestors[i] #parent e.g, 0 to [32, 35, 40, 41, 54, 55, 56, 57, 60, 61]\n",
    "        d = childs_and_distances2ancestors[i]\n",
    "        d2 = childs_and_dis2anc_mut[i]\n",
    "        pi_n[i,j] = d\n",
    "#         pi_n[j,i] = d \n",
    "#         pi_d2[i,j] = d2\n",
    "    pi_n[np.eye(len(pi_n), k=0, dtype='bool')] = 1\n",
    "    \n",
    "#     #### Danny data -mini\n",
    "#     pi_matrix = pd.read_csv('treemut.csv', sep=\",\", header='infer')\n",
    "#     pi_n = np.array(pi_matrix)\n",
    "    \n",
    "    \n",
    "    ### Calculate pairwise distances\n",
    "    for i in range(samp_size): \n",
    "        for j in range(i):\n",
    "            pi[i,j] = 0\n",
    "            #for nodes in reversed(range(ts.num_nodes)):\n",
    "            for nodes in range(ts.num_nodes):\n",
    "                if(pi_n[i][nodes]!=pi_n[j][nodes]):\n",
    "                    pi[i,j] += branch[nodes]\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79753900",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute pairwise distances between and within populations\n",
    "# Pairwise probability\n",
    "# where pi -> calc_pi(ts, branch)\n",
    "\n",
    "def pairwise_pi_wb(pi, deme_config, ndemes, L):\n",
    "    \n",
    "    ## Compute pairwise distances\n",
    "    n = pi.shape[0]\n",
    "    pi_wb = np.zeros(5)\n",
    "    \n",
    "    piw_num = 0.0\n",
    "    piw_den = 0.0\n",
    "    pib_num = 0.0\n",
    "    pib_den = 0.0\n",
    "   \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if(deme_config[i] == deme_config[j]):\n",
    "                piw_num += pi[i,j]\n",
    "                piw_den += L\n",
    "            else:\n",
    "                pib_num += pi[i,j]\n",
    "                pib_den += L\n",
    "                \n",
    "\n",
    "    pi_wb[0] = piw_num\n",
    "    pi_wb[1] = piw_den\n",
    "    pi_wb[2] = pib_num\n",
    "    pi_wb[3] = pib_den\n",
    "    pi_wb[4] = (pi_wb[0]/pi_wb[1]) + (pi_wb[2]/pi_wb[3])\n",
    "    \n",
    "#     print(pi_wb)\n",
    "    \n",
    "    return pi_wb \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7107a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cll(piw_num, piw_den, pib_num, pib_den, theta, M, ndemes):\n",
    "    #Compute canonical parameters\n",
    "    pw = theta * ndemes\n",
    "    pb = theta * (ndemes + (ndemes-1.0)/M)\n",
    "    return pi_wb[0] * log(pw) + (pi_wb[1]-pi_wb[0]) * log(1-pw) + pi_wb[2] * log(pb) + (pi_wb[3]-pi_wb[2]) * log(1-pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7827d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed pairwise composite score (marginal) \n",
    "# Derivative wrt theta of piw_num * log(pw) + (piw_den-piw_num) * log(1-pw) + pib_num * log(pb) + (pib_den-pib_num) * log(1-pb)\n",
    "# Expected value of the gradient of the composite score\n",
    "\n",
    "def pairwise_score(theta, M, ndemes, piw_num, piw_den, pib_num, pib_den):\n",
    "\n",
    "    u_1 =(((piw_num-pib_num)/(theta)) + ((ndemes*(piw_den-piw_num))/(theta*ndemes-1)) - \n",
    "          (((pib_den-pib_num)*(M*ndemes + (ndemes-1)))/((theta*(M*ndemes+(ndemes-1))) - M)))\n",
    "\n",
    "    return u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c8ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-loglikelihood wrt subpopulations\n",
    "# where pairwise_pi_wb_prob -> pairwise_pi_wb(pi, deme_config, ndemes, L) and pi_wb[4] \n",
    "\n",
    "def full_loglikelihood(pairwise_pi_wb_prob):\n",
    "    fl = (np.log(pairwise_pi_wb_prob)).sum()\n",
    "    return -fl   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dbfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected marginal score per datapoint\n",
    "# where p_ij is pairwise_pi_wb(pi, deme_config, ndemes, L) -> pi_wb[4]\n",
    "# and score_der -> pairwise_score(theta, M, ndemes, piw_num, piw_den,...)\n",
    "\n",
    "def E_mscore(score_der,p_ij):\n",
    "    exp_mscore = (score_der * p_ij).sum()\n",
    "    return exp_mscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ab5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in marginal score per datapoint\n",
    "# where p_ij is pairwise_pi_wb(pi, deme_config, ndemes, L) -> pi_wb[4]\n",
    "# and score_der -> pairwise_score(theta, M, ndemes, piw_num, piw_den,...)\n",
    "\n",
    "def Var_mscore(score_der,p_ij):\n",
    "    var_mscore = ((score_der^2 * p_ij) - (E_mscore(score_der,p_ij))^2).sum()\n",
    "    return var_mscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb836f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance in marginal scores for datapoints at the same locus in different genomes\n",
    "# (For datapoints at different loci, the covariance is zero)\n",
    "# where p_ij is pairwise_pi_wb(pi, deme_config, ndemes, L) -> pi_wb[4]\n",
    "# score_der -> pairwise_score(theta, M, ndemes, piw_num, piw_den,...)\n",
    "# score_der_b -> pairwise_score(theta, M, ndemes, 0, 0, pib_num, pib_den)\n",
    "# score_der_w -> pairwise_score(theta, M, ndemes, piw_num, piw_den, 0 ,0)\n",
    "\n",
    "def cov_mscore(score_der_b, score_der_w, score_der, p_ij):\n",
    "    cov_mscore = ((score_der_b * score_der_w * p_ij)-(E_mscore(score_der,p_ij))^2).sum()\n",
    "    return cov_mscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e2e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected composite score\n",
    "# where p_ij is pairwise_pi_wb(pi, deme_config, ndemes, L) -> pi_wb[4]\n",
    "# score_der -> pairwise_score(theta, M, ndemes, piw_num, piw_den,...)\n",
    "\n",
    "def e_composite(score_der,p_ij):\n",
    "    e_u_1 = L*E_mscore(score_der,p_ij)\n",
    "    return e_u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b503e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in composite score\n",
    "# where p_ij is pairwise_pi_wb(pi, deme_config, ndemes, L) -> pi_wb[4]\n",
    "# score_der -> pairwise_score(theta, M, ndemes, piw_num, piw_den,...)\n",
    "# score_der_b -> pairwise_score(theta, M, ndemes, 0, 0, pib_num, pib_den)\n",
    "# score_der_w -> pairwise_score(theta, M, ndemes, piw_num, piw_den, 0 ,0)\n",
    "\n",
    "def var_composite(score_der,score_der_b, score_der_w, theta, mig, p_ij):\n",
    "    var_u_1 = L*Var_mscore(score_der,p_ij)+L*cov_mscore(score_der_b, score_der_w, p_ij)\n",
    "    return var_u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c208e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate composite likelihood and score from pairwise distance matrix \n",
    "### at given parameter values\n",
    "\n",
    "def calc_cl(pi, deme_config, ndemes, L, theta, M):\n",
    "    cl = np.zeros(7)\n",
    "    n = pi.shape[0]\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    piw_num = 0.0\n",
    "    piw_den = 0.0\n",
    "    pib_num = 0.0\n",
    "    pib_den = 0.0\n",
    "   \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if(deme_config[i] == deme_config[j]):\n",
    "                piw_num += pi[i,j]\n",
    "                piw_den += L\n",
    "            else:\n",
    "                pib_num += pi[i,j]\n",
    "                pib_den += L\n",
    "\n",
    "\n",
    "    cl[0] = calc_cl(piw_num, piw_den, pib_num, pib_den, theta, M, ndemes)\n",
    "\n",
    "    # Compute score wrt log of regular parameterization\n",
    "    eps = 1e-6\n",
    "    cl[1] = (calc_cl(piw_num, piw_den, pib_num, pib_den, theta*exp(eps/2), M, ndemes)-calc_cl(piw_num, piw_den, pib_num, pib_den, theta*exp(-eps/2), M, ndemes))/eps\n",
    "    cl[2] = (calc_cl(piw_num, piw_den, pib_num, pib_den, theta, M*exp(eps/2), ndemes)-calc_cl(piw_num, piw_den, pib_num, pib_den, theta, M*exp(-eps/2), ndemes))/eps\n",
    "    \n",
    "    # Separately for within demes\n",
    "    cl[3] = (calc_cl(piw_num, piw_den, 0, 0, theta*exp(eps/2), M, ndemes)-calc_cl(piw_num, piw_den, 0, 0, theta*exp(-eps/2), M, ndemes))/eps\n",
    "    cl[4] = (calc_cl(piw_num, piw_den, 0, 0, theta, M*exp(eps/2), ndemes)-calc_cl(piw_num, piw_den, 0, 0, theta, M*exp(-eps/2), ndemes))/eps\n",
    "\n",
    "    # Separately for between demes\n",
    "    cl[5] = (calc_cl(0, 0, pib_num, pib_den, theta*exp(eps/2), M, ndemes)-calc_cl(0, 0, pib_num, pib_den, theta*exp(-eps/2), M, ndemes))/eps\n",
    "    cl[6] = (calc_cl(0, 0, pib_num, pib_den, theta, M*exp(eps/2), ndemes)-calc_cl(0, 0, pib_num, pib_den, theta, M*exp(-eps/2), ndemes))/eps\n",
    "    return cl\n",
    "\n",
    "## Calculate composite likelihood from sums of pairwise distances at given parameter values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ed8ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The super composite log-likelihood for an alignment of n sequences and L sites is then\n",
    "\n",
    "def calc_cle(pi_wb):\n",
    "    \"\"\"\n",
    "    Calculate composite likelihood estimates from pairwise distance matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pi : Matrix. The list of sequences in the sample.\n",
    "    deme_configs : integer\n",
    "        Number of sequences in the population: 2 * N in a diploid population of N individuals, or N in a\n",
    "        haploid population of N individuals.\n",
    "    L : integer\n",
    "        The length of the sequences\n",
    "    ndemes : Number of populations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    composite log-likelihood for an aligment of n sequences and L length.\n",
    "    \"\"\"\n",
    "    cle = np.zeros(2)\n",
    "    \n",
    "    ##piw =  piw_num/piw_den\n",
    "    piw = pi_wb[0]/pi_wb[1]\n",
    "    ##pib = pib_num/pib_den\n",
    "    pib = pi_wb[2]/pi_wb[3]\n",
    "\n",
    "    \n",
    "    ## CLEs\n",
    "    ## Theta\n",
    "    cle[0] = piw/ndemes\n",
    "    ## M\n",
    "    cle[1] = (cle[0]*(ndemes-1))/(pib-piw)\n",
    "\n",
    "    return cle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b53f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Parameter estimation\n",
    "\n",
    "def Etw(M, D):\n",
    "    \"\"\"\n",
    "    Coalescent expectation time for a pair of sequences sampled within\n",
    "    the same sub-population \n",
    "    \"\"\"\n",
    "    return D\n",
    "\n",
    "def Etb(M, D):\n",
    "    \"\"\"\n",
    "    Coalescent expectation time for a pair of sequences sampled between different \n",
    "    demes\n",
    "    \"\"\"\n",
    "    return D + (D-1)/M\n",
    "\n",
    "def Vtw(M, D):\n",
    "    \"\"\"\n",
    "    Coalescent variance time for a pair of sequences sampled within\n",
    "    the same sub-population \n",
    "    \"\"\"\n",
    "    return 1/(M+1)+(D-1)/M+(M+1)*kw(M,D)+M*(D-1)*kb(M,D)\n",
    "\n",
    "def Vtb(M, D):\n",
    "    \"\"\"\n",
    "    Coalescent variance time for a pair of sequences sampled between different \n",
    "    demes\n",
    "    \"\"\"\n",
    "    return (D-1)*(M+1)/M/M + (cc(M,D)+1)/(M+1)\n",
    "\n",
    "def kw(M, D):\n",
    "    return M*pow(Etb(M,D)/(M+1),2)\n",
    "\n",
    "def kb(M, D):\n",
    "    return (D-2)*pow((Etw(M,D)-Etb(M,D))/(D-1),2)\n",
    "\n",
    "def cc(M, D):\n",
    "    return (M+1)*(M+1)*(kw(M,D)+(D-1)*kb(M,D))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceabea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full likelihood for composite \n",
    "\n",
    "# def calc_cl_B(pi, deme_config, demes, L, theta, M, n):\n",
    "def f(x, theta, M):\n",
    "    #here is the problem\n",
    "#     print('x', x)\n",
    "    B = np.exp(x)\n",
    "#     B = x\n",
    "#     print(B)\n",
    "    if(B<1).any():\n",
    "        B = 1\n",
    "#     print(theta)\n",
    "#     print(M)\n",
    "#     print('B', B)\n",
    "    ## Define the pairwise likelihoods within demes\n",
    "    Et = Etw(M, ndemes)\n",
    "    Vt = Vtw(M, ndemes)\n",
    "    w00 = np.log(1 - 2*theta*Et + theta*theta/B * (Vt + B*Et*Et))\n",
    "    w01 = np.log((theta*Et - theta*theta/B) * (Vt + B*Et*Et))\n",
    "    w11 = np.log(theta*theta/B * (Vt + B*Et*Et))\n",
    "    ## Between demes\n",
    "    Et = Etb(M, ndemes)\n",
    "    Vt = Vtb(M, ndemes)\n",
    "    b00 = np.log(1 - 2*theta*Et + theta*theta/B * (Vt + B*Et*Et))\n",
    "    b01 = np.log((theta*Et - theta*theta/B) * (Vt + B*Et*Et))\n",
    "    b11 = np.log(theta*theta/B * (Vt + B*Et*Et))\n",
    "    ## Compute the composite log-likelihood for B\n",
    "    cl = 0.0\n",
    "    for i in range(n): \n",
    "        for j in range(i): \n",
    "            X00 = (L-pi[i,j])*(L-pi[i,j]-1)/2\n",
    "            X01 = (L-pi[i,j])*pi[i,j]\n",
    "            X11 = pi[i,j]*(pi[i,j]-1)/2\n",
    "            if(deme_config[i]==deme_config[j]): \n",
    "                ## Within demes\n",
    "                cl += X00*w00 + X01*w01 + X11*w11\n",
    "            else:\n",
    "                ## Between demes\n",
    "                cl += X00*b00 + X01*b01 + X11*b11\n",
    "\n",
    "    denftr = (L-1)/2*n*(n-1)/2\n",
    "    super_com = -(cl - denftr)\n",
    "    super_com.astype(int)\n",
    "    \n",
    "    return super_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84c13f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected composite log-likelihood -- Driving value\n",
    "\n",
    "def expcl_deriv(x, theta, M):\n",
    "    B = np.exp(x)\n",
    "    if(B<1).any():\n",
    "        B = 1\n",
    "    ## Within demes\n",
    "    Et_w = Etw(M, ndemes)\n",
    "    Vt_w = Vtw(M, ndemes)\n",
    "    ## Between demes\n",
    "    Et_b = Etb(M, ndemes)\n",
    "    Vt_b = Vtb(M, ndemes)\n",
    "    ## Compute the expected composite log-likelihood for B (driving value)\n",
    "    cl_driving = 0.0\n",
    "    for i in range(n): \n",
    "        for j in range(i): \n",
    "            if(deme_config[i]==deme_config[j]): \n",
    "                ## Within demes\n",
    "                cl_driving+=(-(pow(theta,2)*((pi[i,j]-L)*(-L+pi[i,j]+1))*Vt_w/2*B*(B*pow((Et_w*theta-1),2)+pow(theta,2)*Vt_w)) +\n",
    "                            ((pi[i,j]*theta*(pi[i,j]-L)*Vt_w)/B*(B*Et_w*(Et_w*theta+1)+theta*Vt_w)) -\n",
    "                            (((pi[i,j]-1)*pi[i,j]*Vt_w)/2*B*(B*pow(Et_w,2)+Vt_w)));\n",
    "            else:\n",
    "                ## Between demes\n",
    "                cl_driving+=(-(pow(theta,2)*((pi[i,j]-L)*(-L+pi[i,j]+1))*Vt_b/2*B*(B*pow((Et_b*theta-1),2)+pow(theta,2)*Vt_b)) +\n",
    "                            ((pi[i,j]*theta*(pi[i,j]-L)*Vt_b)/B*(B*Et_b*(Et_b*theta+1)+theta*Vt_b)) -\n",
    "                            (((pi[i,j]-1)*pi[i,j]*Vt_b)/2*B*(B*pow(Et_b,2)+Vt_b)));\n",
    "    \n",
    "    super_com = -(cl_driving)\n",
    "    super_com.astype(int)\n",
    "    ## missing to sum up all the element in the codomain \n",
    "    return super_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56403ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search and calculation of composite likelihood estimators wrt B (who is this guy)\n",
    "def calc_cle_B(pi, deme_config, ndemes,L, theta, M):\n",
    "\n",
    "    n = pi.shape[0]\n",
    "    mean_pi = np.mean(pi)\n",
    "    \n",
    "    gridlen = 20\n",
    "    logBgrid = np.zeros(gridlen)\n",
    "\n",
    "    ### Here is the definition of the Grid\n",
    "    for i in range(gridlen):\n",
    "        logBgrid[i] = np.log(mean_pi)*i/(gridlen-1)\n",
    "\n",
    "    init = np.mean(logBgrid)\n",
    "\n",
    "    raw_funs, polished_x, polished_funs = [], [], []\n",
    "        \n",
    "    res = minimize(varcl_deriv, init, method='Nelder-Mead', args = (theta, M), tol = 1.0e-6)\n",
    "    #res = minimize(f, pt, method='BFGS', args = (theta, M),  tol = 1.0e-8)\n",
    "    polished_x.append(res.x)\n",
    "    polished_funs.append(res.fun)\n",
    "\n",
    "    # evaluation of the solution \n",
    "    solution = res['x']\n",
    "    Bhat = np.exp(solution)\n",
    "    evaluation = f(solution, theta, M)\n",
    "    \n",
    "#     for grid_val in logBgrid:\n",
    "#         fun_eval = f(grid_val, theta, M)\n",
    "#         raw_funs.append(fun_eval)\n",
    "    \n",
    "    print('Solution: f(%s) = %.5f' % (Bhat, evaluation))\n",
    "#     print('raw : %s' % raw_funs)\n",
    "    \n",
    "    return Bhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e45356be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Epi(deme_config, ndemes, L, theta, M):\n",
    "    \"\"\"\n",
    "    Common population genetics models based on composite likelihood, with well-calibrated\n",
    "    quantification of uncertainty.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pi : Matrix. The list of sequences in the sample.\n",
    "    ndemes : integer\n",
    "        Number of sequences in the population: 2 * N in a diploid population of N individuals, or N in a\n",
    "        haploid population of N individuals.\n",
    "    L : integer\n",
    "        The length of the sequences\n",
    "    ndemes : Number of populations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    composite log-likelihood for an aligment of n sequences and L length.\n",
    "    \"\"\"\n",
    "\n",
    "    n = deme_config.shape[0] \n",
    "    Epi = np.zeros((samp_size,samp_size)) \n",
    "    Epiw = L*theta*ndemes\n",
    "    Epib = L*theta*(ndemes + (ndemes-1)/M)\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if(deme_config[i]==deme_config[j]):\n",
    "                Epi[i,j] = Epiw\n",
    "            else:\n",
    "                Epi[j,i] = Epib\n",
    "                            \n",
    "    return Epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4173331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(pi, Epi, deme_config):\n",
    "\n",
    "    err = np.zeros((2,3)) \n",
    "    denom = np.zeros(3)\n",
    "\n",
    "\n",
    "    for i in range(samp_size):\n",
    "        for j in range(i):\n",
    "            \n",
    "            resid = pi[i,j] - Epi[i,j]\n",
    "            #print(resid)\n",
    "            resid2 = (resid)**2\n",
    "            \n",
    "            err[0,0] = np.sum(resid)\n",
    "            err[1,0] = np.sum(resid2)\n",
    "            \n",
    "            denom[0] += 1\n",
    "            \n",
    "            if(deme_config[i]==deme_config[j]):\n",
    "                err[0,1] = np.sum(resid)\n",
    "                err[1,1] = np.sum(resid2)\n",
    "                denom[1] += 1\n",
    "            else:\n",
    "                err[0,2] = np.sum(resid)\n",
    "                err[1,2] = np.sum(resid2)\n",
    "                denom[2] += 1\n",
    "\n",
    "    for k in range(3):\n",
    "        err[0,k]/=denom[k]\n",
    "        err[1,k]/=denom[k]\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fa5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simulate a dataset\n",
    "\n",
    "### Set the true parameter values\n",
    "\n",
    "###Step 1. Global parameters/arguments\n",
    "\n",
    "ndemes = 2\n",
    "samp_size_per_deme = 50\n",
    "samp_size = samp_size_per_deme * ndemes\n",
    "samp_size_dip = (samp_size_per_deme*2) // 2\n",
    "N = 1\n",
    "L = 1e6\n",
    "seed = 111\n",
    "B = 1\n",
    "B2 = 50\n",
    "M = 0.1 \n",
    "theta = 0.01\n",
    "thetaL = (theta*L)\n",
    "thetaLB = (theta*L)/B\n",
    "num_reps = 1\n",
    "simulations = 3\n",
    "nodes = (2*samp_size)-1\n",
    "#np.random.seed([42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba698b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Setting the variables for storing the results\n",
    "\n",
    "piblock = np.zeros((simulations, samp_size,samp_size))\n",
    "pibarblock = np.zeros(simulations)\n",
    "coal_time = np.zeros((samp_size,samp_size))\n",
    "Et_sim = np.zeros((samp_size,samp_size))\n",
    "Et2_sim = np.zeros((samp_size,samp_size))\n",
    "\n",
    "pibar = np.zeros(simulations)\n",
    "pibar_w = np.zeros(simulations)\n",
    "pibar_b = np.zeros(simulations)\n",
    "pi = np.zeros((samp_size,samp_size))\n",
    "\n",
    "Epi = np.zeros((simulations, samp_size,samp_size)) \n",
    "cle_sim = np.zeros((simulations,2))\n",
    "epi_sim = np.zeros((samp_size,samp_size)) \n",
    "cl_B_sim = np.zeros(simulations)\n",
    "cle_B_sim = np.zeros(simulations)\n",
    "cle_B_easy_sim = np.zeros(simulations)\n",
    "cle_sim_mut = np.zeros(simulations)\n",
    "cle_sim_mig = np.zeros(simulations)\n",
    "\n",
    "err_sim = np.zeros((simulations,2,3))\n",
    "data_cle_sim = []\n",
    "data_cle_B_sim = []\n",
    "data_cle_B_easy_sim = []\n",
    "data2_cle_sim = []\n",
    "pi_b = np.zeros((samp_size,samp_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39487cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "952a6c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58796.05656566     0.             0.        ]\n",
      "Second simulation number: 0\n",
      "[0.02159549 0.69892672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x5/vb2nw9156tq5vyxycxy87m31mqdc_q/T/ipykernel_73894/3713639727.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "  (((pi[i,j]-1)*pi[i,j]*Vt_w*(2*B*pow(Et_w,2)+Vt_w))/2*pow(B,2)*pow((B*pow(Et_w,2)+Vt_w),2)));\n",
      "/var/folders/x5/vb2nw9156tq5vyxycxy87m31mqdc_q/T/ipykernel_73894/3713639727.py:17: RuntimeWarning: overflow encountered in multiply\n",
      "  var_cl+=((pow(theta,2)*(L-pi[i,j]-1)*(L-pi[i,j])*Vt_w*(2*B*pow(Et_w*theta-1,2)+pow(theta,2)*Vt_w)/2*pow(B,2)*pow((B*pow((Et_w*theta-1),2)+pow(theta,2)*Vt_w),2)) +\n",
      "/var/folders/x5/vb2nw9156tq5vyxycxy87m31mqdc_q/T/ipykernel_73894/3713639727.py:24: RuntimeWarning: overflow encountered in multiply\n",
      "  (((pi[i,j]-1)*pi[i,j]*Vt_b*(2*B*pow(Et_b,2)+Vt_b))/2*pow(B,2)*pow((B*pow(Et_b,2)+Vt_b),2)));\n",
      "/var/folders/x5/vb2nw9156tq5vyxycxy87m31mqdc_q/T/ipykernel_73894/3713639727.py:22: RuntimeWarning: overflow encountered in multiply\n",
      "  var_cl+=((pow(theta,2)*(L-pi[i,j]-1)*(L-pi[i,j])*Vt_b*(2*B*pow(Et_b*theta-1,2)+pow(theta,2)*Vt_b)/2*pow(B,2)*pow((B*pow((Et_b*theta-1),2)+pow(theta,2)*Vt_b),2)) +\n",
      "/var/folders/x5/vb2nw9156tq5vyxycxy87m31mqdc_q/T/ipykernel_73894/3713639727.py:17: RuntimeWarning: overflow encountered in add\n",
      "  var_cl+=((pow(theta,2)*(L-pi[i,j]-1)*(L-pi[i,j])*Vt_w*(2*B*pow(Et_w*theta-1,2)+pow(theta,2)*Vt_w)/2*pow(B,2)*pow((B*pow((Et_w*theta-1),2)+pow(theta,2)*Vt_w),2)) +\n",
      "/Users/alejandrav/opt/anaconda3/envs/gene/lib/python3.9/site-packages/scipy/optimize/optimize.py:761: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.max(np.abs(fsim[0] - fsim[1:])) <= fatol):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: f([7.18335163e+59]) = 375422031743957440.00000\n",
      "[58796.05656566 99494.9389899      0.        ]\n",
      "Second simulation number: 1\n",
      "[0.0036565  0.02003339]\n",
      "Solution: f([1.67489828e+65]) = 8694750752210656256.00000\n",
      "[58796.05656566 99494.9389899  21149.04222222]\n",
      "Second simulation number: 2\n",
      "[0.00500625 0.22703689]\n",
      "Solution: f([1.55575108e+65]) = 7932627053256153088.00000\n",
      "[array([0.02159549, 0.69892672]), array([0.0036565 , 0.02003339]), array([0.00500625, 0.22703689])]\n",
      "pibars\n",
      "[12957.29142857 19191.50883265 22474.03636735] [ 22226.712  100290.4664  96204.446 ] [ 881940.84848485 3007528.91555554 2985580.84949492]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.38666667e+02, 1.08832653e+03, 1.66479800e+03],\n",
       "       [1.43630080e+09, 2.90191386e+09, 6.92888095e+09]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Testing\n",
    "\n",
    "### testing \n",
    "### Simulate a dataset\n",
    "\n",
    "pi  = np.zeros((simulations, samp_size, samp_size))\n",
    "clebar_mut = np.zeros(simulations)\n",
    "clebar_mig = np.zeros(simulations)\n",
    "p_d_wb = np.zeros((simulations, 5))\n",
    "test = np.zeros(simulations)\n",
    "data_cle_sim = []\n",
    "data_load_msprime = []\n",
    "\n",
    "for sim in range(simulations):\n",
    "    \n",
    "    pi  = np.zeros((simulations, samp_size, samp_size))\n",
    "    pi_cle = np.zeros((simulations, samp_size, samp_size))\n",
    "    sims_reps = simulate_tree_MM(samp_size_per_deme, L)\n",
    "    branch_1 = calc_branches(sims_reps, thetaL)\n",
    "    branch_load = branch_1[0]\n",
    "    branch_length = branch_1[1]\n",
    "    branch_load_msprime = branch_1[2]\n",
    "    data_load_msprime.append(branch_load_msprime)\n",
    "    \n",
    "#     branch_load = np.array(branches['branch_load'])\n",
    "#     branch_load = np.pad(branch_load, (0, 1), 'constant')\n",
    "#     print(branch_load)\n",
    " \n",
    "#     display(SVG(sims_reps.draw_svg(size=(700, 500))))\n",
    "    \n",
    "#     deme_config = np.zeros(samp_size)\n",
    "#     for i in range(samp_size):\n",
    "#         deme_config[i] = i % ndemes\n",
    "    \n",
    "    deme_config = []\n",
    "    for u in sims_reps.nodes():\n",
    "        deme = u.population\n",
    "        deme_config.append(deme)\n",
    "\n",
    "    deme_config = np.array(deme_config[0:samp_size])\n",
    "\n",
    "## Record per-block pairwise distance matrix and mean pairwise distance\n",
    "    piblock[sim] = calc_pi(sims_reps, branch_load)\n",
    "    \n",
    "    \n",
    "#     print('piblock: %s' % (np.mean(piblock[sim])))\n",
    "    pibarblock[sim] = 0.0\n",
    "    \n",
    "    for i in range(samp_size):\n",
    "        for j in range(i):\n",
    "            pibarblock[sim] += piblock[sim][i,j]*2/samp_size/(samp_size-1)\n",
    "            \n",
    "    print(pibarblock)\n",
    "    #Moments (block-wise to reduce computation)\n",
    "    coal_time = calc_pi(sims_reps, branch_length)\n",
    "\n",
    "    for i in range(samp_size):\n",
    "        for j in range(i):\n",
    "            Et_sim[i,j] += coal_time[i,j]/2\n",
    "            Et_sim[j,i] += coal_time[i,j]/2\n",
    "            Et2_sim[i,j] += coal_time[i,j]*coal_time[i,j]/4\n",
    "            Et2_sim[j,i] += coal_time[i,j]*coal_time[i,j]/4\n",
    "    \n",
    "    print(\"Second simulation number: {:d}\".format(sim))\n",
    "    \n",
    "    pi_b = np.zeros((samp_size,samp_size))\n",
    "    pibar[sim] = 0.0\n",
    "    pibar_w[sim] = 0.0\n",
    "    pibar_b[sim] = 0.0\n",
    "    pibar_w_den = 0.0\n",
    "    pibar_b_den = 0.0\n",
    "    \n",
    "    # Independence between pairs\n",
    "    for b in range(B2):\n",
    "        bsim = np.random.randint(int(simulations))\n",
    "#     b_sim = random.sample(range(samp_size), samp_size)\n",
    "#     for bsim in random.sample(range(simulations),simulations):\n",
    "        for i in range(samp_size): \n",
    "            for j in range(i):\n",
    "                pi_b[i,j] += piblock[bsim][i,j]\n",
    "                pibar[sim] += (piblock[bsim][i,j])*2/samp_size/(samp_size-1)\n",
    "                if(deme_config[i]==deme_config[j]):\n",
    "                    pibar_w[sim] += piblock[bsim][i,j] #\n",
    "                    pibar_w_den += 1\n",
    "                else:\n",
    "                    pibar_b[sim] += piblock[bsim][i,j] #\n",
    "                    pibar_b_den += 1\n",
    "    \n",
    "    pibar_w[sim] *= B/pibar_w_den\n",
    "    pibar_b[sim] *= B/pibar_b_den\n",
    "\n",
    "\n",
    "\n",
    "    # Symmetric matrix\n",
    "    for i in range(samp_size):\n",
    "        for j in range(i):\n",
    "            pi_b[j,i] = pi_b[i,j]\n",
    "             \n",
    "    \n",
    "    pi = pi_b\n",
    "#     print(pi)\n",
    "    pi_cle = calc_pi(sims_reps, branch_load)\n",
    "    n = pi.shape[0]\n",
    "    \n",
    "    p_d_wb = pairwise_pi_wb(piblock[sim],deme_config,ndemes,L)\n",
    "    p_ij = p_d_wb[4]\n",
    "\n",
    "    cle_sim = calc_cle(p_d_wb)\n",
    "    data_cle_sim.append(cle_sim)\n",
    "    print(cle_sim)\n",
    "    \n",
    "    cle_sim_mut = cle_sim[0]\n",
    "    cle_sim_mig = cle_sim[1]\n",
    "#     print(cle_sim_mut)\n",
    "    \n",
    "    test = full_loglikelihood(p_ij)\n",
    "    \n",
    "    \n",
    "    cle_B_sim = calc_cle_B(pi,deme_config,ndemes,L,cle_sim_mut,cle_sim_mig)\n",
    "#     data_b = pd.DataFrame(data_cle_B_sim.append(cle_B_sim))\n",
    "    data_cle_B_sim.append(cle_B_sim)\n",
    "    \n",
    "#     cle_B_easy_sim = calc_cle_B(pi,deme_config,ndemes,L,0.01,0.1)\n",
    "# #     data_b_easy = pd.DataFrame(data_cle_B_easy_sim.append(cle_B_easy_sim))\n",
    "#     data_cle_B_easy_sim.append(cle_B_easy_sim)\n",
    "\n",
    "data_cleb = pd.DataFrame(data_cle_sim)\n",
    "data_b = pd.DataFrame(data_cle_B_sim)\n",
    "data_b_easy = pd.DataFrame(data_cle_B_easy_sim)\n",
    "\n",
    "# data_cleB_sim = pd.concat([data_cleb, data_b, data_b_easy], axis=1)\n",
    "# writer = pd.ExcelWriter('cleB_050822.xlsx')\n",
    "# data_cleB_sim.to_excel(writer,'Sheet1')\n",
    "# writer.save()\n",
    "    \n",
    "\n",
    "print(data_cle_sim)\n",
    "\n",
    "print('pibars')\n",
    "print(pibar_w, pibar_b, pibar)\n",
    "\n",
    "\n",
    "# data_cle_sim = pd.DataFrame(data_cle_sim)\n",
    "# data_load_msprime = pd.DataFrame(data_load_msprime)\n",
    "\n",
    "# data_cle_sim = pd.concat([data_cle_sim, data_load_msprime], axis=1)\n",
    "# writer = pd.ExcelWriter('cle.xlsx')\n",
    "# data_cle_sim.to_excel(writer,'Sheet1')\n",
    "# writer.save()\n",
    "\n",
    "# plt.hist(data_cle_sim[0])\n",
    "Epi = calc_Epi(deme_config, ndemes, L, theta, M)\n",
    "calc_error(pi, Epi, deme_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16338109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00500625 0.22703689]\n",
      "[2.45306090e+07 2.45000000e+09 8.01571500e+07 2.50000000e+09\n",
      " 4.20753535e-02]\n",
      "3.168293138004423\n",
      "              0\n",
      "0  7.183352e+59\n",
      "1  1.674898e+65\n",
      "2  1.555751e+65\n"
     ]
    }
   ],
   "source": [
    "print(cle_sim)\n",
    "print(p_d_wb)\n",
    "print(test)\n",
    "print(data_b)\n",
    "# print(data_b_easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7254dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.,      0.,      0., ..., 120000., 120000., 120000.],\n",
       "       [ 20000.,      0.,      0., ..., 120000., 120000., 120000.],\n",
       "       [ 20000.,  20000.,      0., ..., 120000., 120000., 120000.],\n",
       "       ...,\n",
       "       [     0.,      0.,      0., ...,      0.,      0.,      0.],\n",
       "       [     0.,      0.,      0., ...,  20000.,      0.,      0.],\n",
       "       [     0.,      0.,      0., ...,  20000.,  20000.,      0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_Epi(deme_config, ndemes, L, theta, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba89182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
